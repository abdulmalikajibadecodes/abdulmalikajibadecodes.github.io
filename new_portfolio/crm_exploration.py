# -*- coding: utf-8 -*-
"""crm_exploration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13ZWwviF6GE7jtECGj8F7oG9WOuvizQIx

# Production rate optimization in Oil Wells Using the CRM Model and Machine Learning Techniques

#### By Abdulmalik Ajibade
"""

import pandas as pd
import numpy as np
from pywaterflood import CRM

production_data = pd.read_csv('C:/Users/USER/Desktop/DATA SCIENCE/CRM/data/raw/production.csv', header=None).values
injection_data = pd.read_csv('C:/Users/USER/Desktop/DATA SCIENCE/CRM\data/raw/injection.csv', header=None).values
time_data = pd.read_csv('C:/Users/USER/Desktop/DATA SCIENCE/CRM/data/raw/time.csv', header=None).values[:, 0]

print("Dimensions of Production Data:", production_data.shape)
print("Dimensions of Injection Data:", injection_data.shape)
print("Dimensions of Time Data:", time_data.shape)

"""The dataset represents a field with 5 producing wells and 4 injection wells over a period of 298 time steps. The dimensions of the data are as follows:

- **Production Data**: 298 time steps x 5 producing wells
- **Injection Data**: 298 time steps x 4 injection wells
- **Time Data**: 298 time steps
"""

from sklearn.metrics import mean_absolute_error, mean_squared_error

crm = CRM(tau_selection='per-pair', constraints='up-to one')
crm.fit(production_data, injection_data, time_data)
q_pred = crm.predict()
residuals = crm.residual()
import matplotlib.pyplot as plt

crm_mae = mean_absolute_error(production_data, q_pred, multioutput='raw_values')
crm_rmse = np.sqrt(mean_squared_error(production_data, q_pred, multioutput='raw_values'))


print("Mean Absolute Error (MAE) for each well:", crm_mae)
print("Root Mean Squared Error (RMSE) for each well:", crm_rmse)


num_wells = production_data.shape[1]
time_steps = time_data

plt.figure(figsize=(15, 10))
for i in range(num_wells):
    plt.subplot(num_wells, 1, i + 1)
    plt.plot(time_steps, production_data[:, i], label='Actual')
    plt.plot(time_steps, q_pred[:, i], label='Predicted')
    plt.title(f'Producer {i + 1} - RMSE: {crm_rmse[i]:.2f}')
    plt.xlabel('Time')
    plt.ylabel('Production Rate')
    plt.legend()

plt.tight_layout()

"""### Model Performance Analysis

The CRM model was fairly able to predict the production rates for each well. The predicted values closely follow the actual production rates, indicating that the model captures the general trend of the data. However, the model struggles to predict significant changes in production rates, either higher than normal or lower than normal. This is particularly evident in Producer Well 4, where the Root Mean Squared Error (RMSE) is the highest among all wells.

Incorporating reliable BHP data into the model could potentially improve its accuracy by providing more context and information about the well's performance.

### Machine Learning Methods

While the CRM model establishes a solid baseline, employing machine learning methods to model the residuals has the potential to enhance the accuracy of our results.

To demonstrate this, I will implement both linear regression, which serves as a statistical approach, and a machine learning model, specifically a Random Forest regressor, to model these residuals and subsequently see if they improve the final predictions or not.

### Residuals
"""

plt.figure(figsize=(15, 10))
for i in range(num_wells):
    plt.subplot(num_wells, 1, i + 1)
    plt.plot(time_steps, residuals[:, i], label=f'Residuals for Well {i + 1}')
    plt.title(f'Residuals for Producer {i + 1}')
    plt.xlabel('Time')
    plt.ylabel('Residuals')
    plt.legend()

plt.tight_layout()
plt.show()

"""It is evident that the residuals demonstrate a non-linear pattern.

#### Modelling residuals using LR and 3rd order polynomial
"""

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
linear_residuals_pred = linear_model.predict(X_test)
linear_final_predictions = q_pred + linear_model.predict(time_data_reshaped).reshape(-1, production_data.shape[1])

linear_rmse_per_well = np.sqrt(mean_squared_error(production_data, linear_final_predictions, multioutput='raw_values'))
print("Linear Regression RMSE per well:", linear_rmse_per_well)

# Polynomial Regression
poly = PolynomialFeatures(degree=3)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)
time_data_poly = poly.transform(time_data_reshaped)

poly_model = LinearRegression()
poly_model.fit(X_train_poly, y_train)
poly_residuals_pred = poly_model.predict(X_test_poly)
poly_final_predictions = q_pred + poly_model.predict(time_data_poly).reshape(-1, production_data.shape[1])

poly_rmse_per_well = np.sqrt(mean_squared_error(production_data, poly_final_predictions, multioutput='raw_values'))
print("Polynomial Regression RMSE per well:", poly_rmse_per_well)

# Visualization
plt.figure(figsize=(20, 20))
for i in range(production_data.shape[1]):  # Loop through each well
    plt.subplot(production_data.shape[1], 1, i + 1)
    plt.plot(time_data, production_data[:, i], label='Actual', color='blue')
    plt.plot(time_data, linear_final_predictions[:, i], label='Linear Predicted', color='red')
    plt.plot(time_data, poly_final_predictions[:, i], label='Polynomial Predicted', color='green')
    plt.plot(time_data, q_pred[:, i], label='CRM Predicted', color='orange')
    plt.title(f'Producer {i + 1} - Linear RMSE: {linear_rmse_per_well[i]:.2f},\
               Poly RMSE: {poly_rmse_per_well[i]:.2f},   \
                CRM RMSE: {crm_rmse[i]:.2f}')
    plt.xlabel('Time')
    plt.ylabel('Production Rate')
    plt.legend()

plt.tight_layout()
plt.show()

"""The linear regression and polynomial regression models showed little to no improvements. This is understandable given the non-linear behavior of the residuals, which these models may struggle to capture effectively.

#### RANDOM FOREST MODEL
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

time_data_reshaped = time_data.reshape(-1, 1)


X_train, X_test, y_train, y_test = train_test_split(time_data_reshaped, residuals, test_size=0.2, random_state=42)


model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)


residuals_pred = model.predict(X_test)


final_predictions = q_pred + model.predict(time_data_reshaped).reshape(-1, production_data.shape[1])  # Ensure the shape matches


rf_mae = mean_absolute_error(y_test, residuals_pred)
rf_rmse = np.sqrt(mean_squared_error(production_data, \
final_predictions, multioutput='raw_values'))
print("Random Forest RMSE:", rf_rmse)

print("Mean Absolute Error (MAE):", rf_mae)
print("Root Mean Squared Error (RMSE):", rf_rmse)


plt.figure(figsize=(20, 15))
for i in range(production_data.shape[1]):
    plt.subplot(production_data.shape[1], 1, i + 1)
    plt.plot(time_data, production_data[:, i], label='Actual', color='blue')
    plt.plot(time_data, q_pred[:, i], label='CRM Predicted', color='orange')
    plt.plot(time_data, final_predictions[:, i], label='Final Predicted', color='red')
    plt.title(f'Producer {i + 1} - CRM RMSE: {crm_rmse[i]:.2f}, Final RMSE: {rf_rmse[i]:.2f}')
    plt.xlabel('Time')
    plt.ylabel('Production Rate')
    plt.legend()

plt.tight_layout()
plt.show()

"""Modeling the residuals using Random Forest significantly enhances prediction accuracy, particularly evident in the case of producer well 4, where the RMSE decreased from 245 to 66.49. With the integration of reliable bhp data the prediction accuracy can be much more enhanced.

This shows a potential of advanced predictive analytics in optimizing oil production strategies and encourages further exploration of machine learning techniques to refine forecasting.
"""





